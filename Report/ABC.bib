@article{Rubin1984,
author = {Rubin, Donald B.},
file = {:Users/ellakaye/Box Sync/Maths and Stats/Probability and Stats/Papers/Rubin (1984) Bayesianly justifiable and relevant frequeny calculations for the applied statistician.pdf:pdf},
journal = {The Annal},
number = {4},
pages = {1151--1172},
title = {{Bayesianly Justifiable and Relevant Frequency Calculations for the Applied Statistician}},
volume = {12},
year = {1984}
}
@article{Wilkinson2013,
abstract = {Approximate Bayesian computation (ABC) or likelihood-free inference algorithms are used to find approximations to posterior distributions without making explicit use of the likelihood function, depending instead on simulation of sample data sets from the model. In this paper we show that under the assumption of the existence of a uniform additive model error term, ABC algorithms give exact results when sufficient summaries are used. This interpretation allows the approximation made in many previous application papers to be understood, and should guide the choice of metric and tolerance in future work. ABC algorithms can be generalized by replacing the 0-1 cut-off with an acceptance probability that varies with the distance of the simulated data from the observed data. The acceptance density gives the distribution of the error term, enabling the uniform error usually used to be replaced by a general distribution. This generalization can also be applied to approximate Markov chain Monte Carlo algorithms. In light of this work, ABC algorithms can be seen as calibration techniques for implicit stochastic models, inferring parameter values in light of the computer model, data, prior beliefs about the parameter values, and any measurement or model errors.},
archivePrefix = {arXiv},
arxivId = {0811.3355},
author = {Wilkinson, Richard David},
doi = {10.1515/sagmb-2013-0010},
eprint = {0811.3355},
file = {:Users/ellakaye/Box Sync/Maths and Stats/Probability and Stats/Papers/Wilkinson (2013) Approximate Bayesian computation (ABC) gives exact results under the assumptions of model error.pdf:pdf},
isbn = {15446115},
issn = {15446115},
journal = {Statistical Applications in Genetics and Molecular Biology},
keywords = {Approximate Bayesian computation,Calibration,Implicit inference,Likelihood-free inference,Monte Carlo},
number = {2},
pages = {129--141},
pmid = {23652634},
title = {{Approximate Bayesian computation (ABC) gives exact results under the assumption of model error}},
volume = {12},
year = {2013}
}
@article{Blum2013,
abstract = {Approximate Bayesian computation (ABC) methods make use of comparisons between simulated and observed summary statistics to over-come the problem of computationally intractable likelihood functions. As the practical implementation of ABC requires computations based on vectors of summary statistics, rather than full data sets, a central question is how to derive low-dimensional summary statistics from the observed data with min-imal loss of information. In this article we provide a comprehensive review and comparison of the performance of the principal methods of dimension reduction proposed in the ABC literature. The methods are split into three nonmutually exclusive classes consisting of best subset selection methods, projection techniques and regularization. In addition, we introduce two new methods of dimension reduction. The first is a best subset selection method based on Akaike and Bayesian information criteria, and the second uses ridge regression as a regularization procedure. We illustrate the performance of these dimension reduction techniques through the analysis of three challeng-ing models and data sets.},
archivePrefix = {arXiv},
arxivId = {arXiv:1202.3819v3},
author = {Blum, M G B and Nunes, M A and Prangle, D and Sisson, S A},
doi = {10.1214/12-STS406},
eprint = {arXiv:1202.3819v3},
file = {:Users/ellakaye/Downloads/Blum et al (2013) Comparative review of Dimension reduction methods in ABC.pdf:pdf},
isbn = {0883-4237},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {Approximate Bayesian computation,dimension reduction,likelihood-free inference,regularization,variable selection},
number = {2},
pages = {189--208},
title = {{A Comparative Review of Dimension Reduction Methods in Approximate Bayesian Computation}},
volume = {28},
year = {2013}
}
@article{Blum2010,
abstract = {Approximate Bayesian Computation is a family of likelihood-free inference techniques that are well-suited to models defined in terms of a stochastic generating mechanism. In a nutshell, Approximate Bayesian Computation proceeds by computing summary statistics s{\_}obs from the data and simulating summary statistics for different values of the parameter theta. The posterior distribution is then approximated by an estimator of the conditional density g(theta|s{\_}obs). In this paper, we derive the asymptotic bias and variance of the standard estimators of the posterior distribution which are based on rejection sampling and linear adjustment. Additionally, we introduce an original estimator of the posterior distribution based on quadratic adjustment and we show that its bias contains a fewer number of terms than the estimator with linear adjustment. Although we find that the estimators with adjustment are not universally superior to the estimator based on rejection sampling, we find that they can achieve better performance when there is a nearly homoscedastic relationship between the summary statistics and the parameter of interest. To make this relationship as homoscedastic as possible, we propose to use transformations of the summary statistics. In different examples borrowed from the population genetics and epidemiological literature, we show the potential of the methods with adjustment and of the transformations of the summary statistics. Supplemental materials containing the details of the proofs are available online.},
archivePrefix = {arXiv},
arxivId = {0904.0635},
author = {Blum, Michael G B},
doi = {10.1198/jasa.2010.tm09448},
eprint = {0904.0635},
file = {:Users/ellakaye/Downloads/Blum (2010) Approximate Bayesian Computation.pdf:pdf},
isbn = {0162-1459},
issn = {0162-1459},
journal = {Journal of American Statistical Association},
keywords = {Conditional density estimation,Implicit statistic,conditional density estimation,implicit statistical model,kernel regression,local polynomial,simulation-based infer-},
number = {491},
pages = {1178--1187},
pmid = {283695300032},
title = {{Approximate Bayesian Computation: a nonparametric perspective}},
url = {http://arxiv.org/abs/0904.0635},
volume = {105},
year = {2010}
}
@article{Csillery2012,
author = {Csill{\'{e}}ry, K and Fran{\c{c}}ois, O and Blum, Mgb},
file = {:Users/ellakaye/Downloads/abcvignette.pdf:pdf},
journal = {202.162.217.53},
pages = {1--21},
title = {{Approximate Bayesian Computation (ABC) in R: A Vignette}},
url = {ftp://202.162.217.53/CRAN/web/packages/abc/vignettes/abcvignette.pdf},
year = {2012}
}
@article{Fearnhead2012,
abstract = {Summary. Many modern statistical applications involve inference for complex stochastic models, where it is easy to simulate from the models, but impossible to calculate likelihoods. Approximate Bayesian computation (ABC) is a method of inference for such models. It replaces calculation of the likelihood by a step which involves simulating artificial data for different parameter values, and comparing summary statistics of the simulated data with summary statistics of the observed data. Here we show how to construct appropriate summary statistics for ABC in a semi-automatic manner. We aim for summary statistics which will enable inference about certain parameters of interest to be as accurate as possible. Theoretical results show that optimal summary statistics are the posterior means of the parameters. Although these cannot be calculated analytically, we use an extra stage of simulation to estimate how the posterior means vary as a function of the data; and we then use these estimates of our summary statistics within ABC. Empirical results show that our approach is a robust method for choosing summary statistics that can result in substantially more accurate ABC analyses than the ad hoc choices of summary statistics that have been proposed in the literature. We also demonstrate advantages over two alternative methods of simulation-based inference.},
archivePrefix = {arXiv},
arxivId = {arXiv:1201.1314v1},
author = {Fearnhead, Paul and Prangle, Dennis},
doi = {10.1111/j.1467-9868.2011.01010.x},
eprint = {arXiv:1201.1314v1},
file = {:Users/ellakaye/Library/Application Support/Mendeley Desktop/Downloaded/Fearnhead, Prangle - 2012 - Constructing summary statistics for approximate Bayesian computation Semi-automatic approximate Bayesian com.pdf:pdf},
isbn = {1369-7412},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Indirect inference,Likelihood-free inference,Markov chain Monte Carlo methods,Simulation,Stochastic kinetic networks},
number = {3},
pages = {419--474},
title = {{Constructing summary statistics for approximate Bayesian computation: Semi-automatic approximate Bayesian computation}},
volume = {74},
year = {2012}
}
@article{Marin2012,
abstract = {Approximate Bayesian Computation (ABC) methods, also known as likelihood-free techniques, have appeared in the past ten years as the most satisfactory approach to intractable likelihood problems, first in genetics then in a broader spectrum of applications. However, these methods suffer to some degree from calibration difficulties that make them rather volatile in their implementation and thus render them suspicious to the users of more traditional Monte Carlo methods. In this survey, we study the various improvements and extensions brought on the original ABC algorithm in recent years.},
archivePrefix = {arXiv},
arxivId = {arXiv:1101.0955v1},
author = {Marin, J M and Pudlo, P and Robert, C P and Ryder, R J},
doi = {10.1007/s11222-011-9288-2},
eprint = {arXiv:1101.0955v1},
file = {:Users/ellakaye/Box Sync/Maths and Stats/Probability and Stats/Papers/Marin et al (2012) Approximate Bayesian computational methods.pdf:pdf},
isbn = {0960-3174},
issn = {0960-3174},
journal = {Statistics and Computing},
keywords = {ABC methodology,Bayesian model choice,Bayesian statistics,CHOICE,CRITICISM,DENSITIES,DIYABC,DYNAMICAL-SYSTEMS,INFERENCE,LIKELIHOODS,Likelihood-free methods,MARGINAL,MODEL SELECTION,PARAMETER-ESTIMATION,PHYLOGEOGRAPHY,SEQUENTIAL MONTE-CARLO},
number = {6},
pages = {1167--1180},
title = {{Approximate Bayesian computational methods}},
url = {<Go to ISI>://WOS:000310232000002},
volume = {22},
year = {2012}
}
@article{Nunes2015,
author = {Nunes, Matthew A and Prangle, Dennis},
file = {:Users/ellakaye/Box Sync/My Education/OxWaSP/Modules/Module 6/abctools article.pdf:pdf},
issn = {20734859},
journal = {The R journal},
number = {2},
pages = {1--16},
title = {{abctools : An R Package for Tuning Approximate Bayesian Computation Analyses}},
volume = {7},
year = {2015}
}
@article{Robert2014,
author = {Robert, Christian P. and Cornuet, Jean-Marie and Marin, Jean-Michel and Pillai, Natesh S .},
doi = {10.1073/pnas.1102900},
file = {:Users/ellakaye/Box Sync/Maths and Stats/Probability and Stats/Papers/Robert et al (2011) Lack of confidence in ABC model choice.pdf:pdf},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
number = {37},
pages = {15112--15117},
title = {{Lack of confidence in approximate Bayesian computation model choice}},
volume = {108},
year = {2014}
}
@article{allingham2009,
  title={Bayesian estimation of quantile distributions},
  author={Allingham, David and King, RAR and Mengersen, Kerrie L},
  journal={Statistics and Computing},
  volume={19},
  number={2},
  pages={189--201},
  year={2009},
  publisher={Springer}
}
@article{beaumont2002,
  title={Approximate Bayesian computation in population genetics},
  author={Beaumont, Mark A and Zhang, Wenyang and Balding, David J},
  journal={Genetics},
  volume={162},
  number={4},
  pages={2025--2035},
  year={2002},
  publisher={Genetics Soc America}
}